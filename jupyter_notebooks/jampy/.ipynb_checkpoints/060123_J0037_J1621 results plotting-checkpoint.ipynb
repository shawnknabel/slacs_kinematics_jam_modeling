{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06/02/23 - Copied from 060123_jam_bayes_adamet_emcee_J1621.ipynb\n",
    "# Visualizing the results from yesterday's AdaMet and Emcee runs on J0037 and J1621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "\n",
    "# import general libraries and modules\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\", module = \"matplotlib\\..*\" )\n",
    "warnings.filterwarnings( \"ignore\", module = \"plotbin\\..*\" )\n",
    "import os\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "def tick():\n",
    "    return datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")\n",
    "\n",
    "# astronomy/scipy\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from scipy.ndimage import rotate\n",
    "from scipy.ndimage import map_coordinates\n",
    "from scipy.optimize import least_squares as lsq\n",
    "from astropy.convolution import convolve, convolve_fft, Gaussian2DKernel\n",
    "#from astropy.cosmology import Planck15 as cosmo # I took 15 because for some reason Planck18 isn't in this astropy install #Planck18 as cosmo  # Planck 2018\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "cosmo = FlatLambdaCDM(H0=70, Om0=0.3, Tcmb0=2.725)\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "# mge fit\n",
    "import mgefit\n",
    "from mgefit.find_galaxy import find_galaxy\n",
    "from mgefit.mge_fit_1d import mge_fit_1d\n",
    "from mgefit.sectors_photometry import sectors_photometry\n",
    "from mgefit.mge_fit_sectors import mge_fit_sectors\n",
    "from mgefit.mge_print_contours import mge_print_contours\n",
    "from mgefit.mge_fit_sectors_regularized import mge_fit_sectors_regularized\n",
    "\n",
    "# jam\n",
    "from jampy.jam_axi_proj import jam_axi_proj\n",
    "from jampy.jam_axi_proj import rotate_points\n",
    "from jampy.jam_axi_proj import bilinear_interpolate\n",
    "from jampy.mge_half_light_isophote import mge_half_light_isophote\n",
    "from plotbin.plot_velfield import plot_velfield\n",
    "from plotbin.sauron_colormap import register_sauron_colormap\n",
    "register_sauron_colormap()\n",
    "from pafit.fit_kinematic_pa import fit_kinematic_pa\n",
    "from jampy.jam_axi_proj import jam_axi_proj\n",
    "from jampy.mge_radial_mass import mge_radial_mass\n",
    "from plotbin.symmetrize_velfield import symmetrize_velfield\n",
    "\n",
    "# adamet\n",
    "from adamet.adamet import adamet\n",
    "from adamet.corner_plot import corner_plot\n",
    "# emcee\n",
    "import emcee\n",
    "import corner\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# my functions\n",
    "import sys\n",
    "sys.path.append(\"/home/shawnknabel/Documents/slacs_kinematics/my_python_packages\")\n",
    "from slacs_ani_mass_jam import osipkov_merritt_model\n",
    "from slacs_ani_mass_jam import osipkov_merritt_generalized_model\n",
    "from slacs_ani_mass_jam import inner_outer_anisotropy_model\n",
    "from slacs_ani_mass_jam import nfw_generalized_model\n",
    "from slacs_ani_mass_jam import dark_halo_mge\n",
    "from slacs_ani_mass_jam import total_mass_mge\n",
    "from slacs_ani_mass_jam import jam_lnprob\n",
    "from slacs_ani_mass_jam import jam_lnprob_power_law\n",
    "from slacs_ani_mass_jam import jam_lnprob_nfw_constbeta\n",
    "from slacs_ani_mass_jam import jam_lnprob_nfwgen_constbeta\n",
    "from slacs_ani_mass_jam import jam_lnprob_nfw_om\n",
    "from slacs_ani_mass_jam import jam_lnprob_nfwgen_om\n",
    "from slacs_ani_mass_jam import summary_plot\n",
    "from slacs_ani_mass_jam import save_fit_parameters\n",
    "from slacs_ani_mass_jam import get_power_law_slope\n",
    "from slacs_ani_mass_jam import jampy_details\n",
    "from slacs_ani_mass_jam import prepare_to_jam\n",
    "from slacs_ani_mass_jam import space_jam\n",
    "from slacs_mge_jampy import make_gaussian\n",
    "\n",
    "################################################################\n",
    "# some needed information\n",
    "kcwi_scale = 0.1457  # arcsec/pixel\n",
    "hst_scale = 0.050 # ACS/WFC\n",
    "# B band (F435W) dust extinction ~ 0.116 from https://irsa.ipac.caltech.edu/applications/DUST/\n",
    "#extinction = 0.116\n",
    "### photometric zeropoint for F435W as of 2007 was 25.745\n",
    "#photometric_zeropoint = 25.745\n",
    "# redshift, convert to angular diameter dist in Mpc\n",
    "#z = 0.195\n",
    "#distance = cosmo.angular_diameter_distance(z).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs will be in /data/raw_data/KECK_KCWI_SLACS_kinematics_shawn/jam_outputs/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################################################\n",
    "\n",
    "date_of_kin = '2023-02-28_2'\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Directories and files\n",
    "\n",
    "# data directory\n",
    "data_dir = '/data/raw_data/KECK_KCWI_SLACS_kinematics_shawn/'\n",
    "hst_dir = '/data/raw_data/HST_SLACS_ACS/kcwi_kinematics_lenses/'\n",
    "tables_dir = f'{data_dir}tables/'\n",
    "mosaics_dir = f'{data_dir}mosaics/'\n",
    "kinematics_full_dir = f'{data_dir}kinematics/'\n",
    "kinematics_dir =f'{kinematics_full_dir}{date_of_kin}/'\n",
    "jam_output_dir = f'{data_dir}jam_outputs/'\n",
    "# create a directory for JAM outputs\n",
    "Path(jam_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(f'Outputs will be in {jam_output_dir}')\n",
    "print()\n",
    "\n",
    "# target SN for voronoi binning\n",
    "vorbin_SN_targets = np.array([10, 15, 20])\n",
    "\n",
    "#################################################\n",
    "# objects\n",
    "obj_names = ['SDSSJ0029-0055',\n",
    "             'SDSSJ0037-0942',\n",
    "             'SDSSJ0330-0020',\n",
    "             'SDSSJ1112+0826',\n",
    "             'SDSSJ1204+0358',\n",
    "             'SDSSJ1250+0523',\n",
    "             'SDSSJ1306+0600',\n",
    "             'SDSSJ1402+6321',\n",
    "             'SDSSJ1531-0105',\n",
    "             'SDSSJ1538+5817',\n",
    "             'SDSSJ1621+3931',\n",
    "             'SDSSJ1627-0053',\n",
    "             'SDSSJ1630+4520',\n",
    "             'SDSSJ2303+1422'\n",
    "            ]\n",
    "\n",
    "#################################################\n",
    "\n",
    "paper_table = pd.read_csv(f'{tables_dir}paper_table_051223.csv')\n",
    "zs = paper_table['zlens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to collect and save all the attributes I need for jampy\n",
    "class jampy_details:\n",
    "    \n",
    "    def __init__(details, surf_density, mge_sigma, q, kcwi_sigmapsf, Vrms_bin, dVrms_bin, V_bin, dV_bin, xbin_phot, ybin_phot, reff):\n",
    "        details.surf_density=surf_density \n",
    "        details.mge_sigma=mge_sigma\n",
    "        details.q=q \n",
    "        details.kcwi_sigmapst=kcwi_sigmapsf \n",
    "        details.Vrms_bin=Vrms_bin \n",
    "        details.dVrms_bind=dVrms_bin\n",
    "        details.V_bin=V_bin \n",
    "        details.dV_bin=dV_bin \n",
    "        details.xbin_phot=xbin_phot \n",
    "        details.ybin_phot=ybin_phot\n",
    "        details.reff=reff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "______________________\n",
    "\n",
    "# Dynamical Modeling with JAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_to_jam(obj_name, file_dir, SN):\n",
    "\n",
    "    # take the surface density, etc from mge saved parameters\n",
    "    with open(f'{file_dir}{obj_name}_{SN}_details_for_jampy.pkl', 'rb') as f:\n",
    "        tommy_pickles = pickle.load(f)\n",
    "\n",
    "    surf = tommy_pickles.surf_density\n",
    "    sigma = tommy_pickles.mge_sigma\n",
    "    qObs = tommy_pickles.q\n",
    "    #kcwi_sigmapsf = tommy_pickles.kcwi_sigmapst # mistake in name\n",
    "    kcwi_sigmapsf = tommy_pickles.kcwi_sigmapsf\n",
    "    Vrms_bin = tommy_pickles.Vrms_bin\n",
    "    #dVrms_bin = tommy_pickles.dVrms_bin \n",
    "    dVrms_bin = tommy_pickles.dVrms_bind # mistake in name\n",
    "    V_bin = tommy_pickles.V_bin\n",
    "    dV_bin = tommy_pickles.dV_bin\n",
    "    xbin_phot = tommy_pickles.xbin_phot\n",
    "    ybin_phot = tommy_pickles.ybin_phot\n",
    "    reff = tommy_pickles.reff\n",
    "    \n",
    "    return (surf, sigma, qObs, kcwi_sigmapsf, Vrms_bin, dVrms_bin, V_bin, dV_bin, xbin_phot, ybin_phot, reff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to view previous samplings\n",
    "\n",
    "def get_best_param_err (obj_name, SN, model, anisotropy, align, model_dir=None, date_time=None, run_id=None):\n",
    "\n",
    "    '''\n",
    "    obj_name and number steps to try it out. Start all with the same priors.\n",
    "    '''\n",
    "\n",
    "    obj_abbr = obj_name[4:9] # e.g. J0029\n",
    "    #zlens = zlens[i]\n",
    "    #distance = cosmo.angular_diameter_distance(zlens).value\n",
    "\n",
    "    mos_dir = f'{mosaics_dir}{obj_name}/' # directory with all files of obj_name\n",
    "    kin_dir = f'{kinematics_dir}{obj_name}/'\n",
    "    jam_dir = f'{jam_output_dir}{obj_name}/'\n",
    "    \n",
    "    if obj_abbr=='J0330':\n",
    "        target_kin_dir = f'{kin_dir}target_sn_{SN}/{obj_name}_{SN}_final_kinematics/no_g/'\n",
    "    else:\n",
    "        target_kin_dir = f'{kin_dir}target_sn_{SN}/{obj_name}_{SN}_marginalized_gnog_final_kinematics/'\n",
    "    target_jam_dir = f'{jam_dir}target_sn_{SN}/'\n",
    "    \n",
    "    # Get model directory\n",
    "    if model_dir is not None:\n",
    "        model_dir = f'{model_dir}/'\n",
    "    elif date_time is not None and run_id is None:\n",
    "        model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_{SN}_{model}_{anisotropy}_{align}/'\n",
    "    elif date_time is None:\n",
    "        date_time = datetime.now().strftime(\"%Y_%m_%d\")#-%I_%M_%S_%p\")\n",
    "        model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_{SN}_{model}_{anisotropy}_{align}/'\n",
    "    elif date_time is not None and run_id is not None:\n",
    "        model_dir =  f'{target_jam_dir}{obj_name}_model_{date_time}_v{run_id}_{SN}_{model}_{anisotropy}_{align}/'   \n",
    "    else:\n",
    "        print('something wrong')\n",
    "    \n",
    "    #\n",
    "    bestfit = np.genfromtxt(f'{model_dir}{obj_name}_{date_time}_bestfit_parameters.txt', delimiter='')\n",
    "    err = np.genfromtxt(f'{model_dir}{obj_name}_{date_time}_bestfit_parameters_error.txt', delimiter='')\n",
    "    pars = np.genfromtxt(f'{model_dir}{obj_name}_{date_time}_parameters_fit.txt', delimiter='')\n",
    "    lnprob = np.genfromtxt(f'{model_dir}{obj_name}_{date_time}_likelihood.txt', delimiter='') \n",
    "    bounds = np.genfromtxt(f'{model_dir}{obj_name}_{date_time}_bounds.txt', delimiter='')\n",
    "    rms_model = np.genfromtxt(f'{model_dir}{obj_name}_{date_time}_rms_model.txt', delimiter='')\n",
    "    #print(labels)\n",
    "    with open(f\"{model_dir}{obj_name}_{date_time}_kwargs.pkl\", \"rb\") as f:\n",
    "        kwargs = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    chi2 = -2*jam_lnprob(bestfit, **kwargs)  # Compute chi2 of model at best fit location\n",
    "    \n",
    "    return bestfit, err, pars, lnprob, chi2, bounds, rms_model#, labels\n",
    "    \n",
    "# weighted gaussian to compare the models..\n",
    "def weighted_gaussian(xx, mu, sig, c2):\n",
    "    yy = np.zeros(shape=xx.shape)\n",
    "    for i in range(len(xx)):\n",
    "        yy[i] = np.exp(-np.power(xx[i] - mu, 2.) / (2 * np.power(sig, 2.))) * np.exp(-0.5 * c2)\n",
    "    return yy\n",
    "\n",
    "\n",
    "def get_labels(model, anisotropy):\n",
    "    if model=='power_law':\n",
    "        if anisotropy=='const':              \n",
    "            labels = [r'$\\gamma$', r\"$q_{\\rm min}$\", r\"$\\sigma_z/\\sigma_R$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "        elif anisotropy=='OM':\n",
    "            labels = [r'$\\gamma$', r\"$q_{\\rm min}$\", r\"$a_{ani}$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "    elif model=='nfw':\n",
    "        if anisotropy=='const':\n",
    "            labels = [r\"$f_{\\rm DM}$\", r\"$q_{\\rm min}$\", r\"$\\sigma_z/\\sigma_R$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "        elif anisotropy=='OM':     \n",
    "            labels = [r\"$f_{\\rm DM}$\", r\"$q_{\\rm min}$\", r\"$a_{ani}$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_plot(obj_name, date_time, model_dir, jam_prob_func, model_name, \\\n",
    "                     pars=None, lnprob=None, labels=None, bounds=None, \\\n",
    "                     kwargs=None, save=False, load=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Print the best fitting solution with uncertainties.\n",
    "    Plot the final corner plot with the best fitting JAM model.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    xbin = kwargs['xbin']\n",
    "    ybin = kwargs['ybin']\n",
    "    goodbins = kwargs['goodbins']\n",
    "    rms = kwargs['rms']\n",
    "    \n",
    "    if load == True:\n",
    "        jam_test_dir = model_dir #f'{data_dir}jam_testing/2023_01_31/'\n",
    "        pars = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*parameters_fit.txt')[0])\n",
    "        lnprob = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*likelihood.txt')[0])\n",
    "        labels = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*labels.txt')[0], delimiter='  ', dtype='<U20')\n",
    "        bounds = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*bounds.txt')[0])\n",
    "        bestfit = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*bestfit_parameters.txt')[0])\n",
    "        perc = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*bestfit_parameters_percentile.txt')[0])\n",
    "        sig_bestfit = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*bestfit_parameters_error.txt')[0])\n",
    "        surf_potential = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*surf_potential.txt')[0])\n",
    "        rms_model = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*rms_model.txt')[0])\n",
    "        flux_model = np.genfromtxt(glob.glob(f'{jam_test_dir}*{obj_name}*/*flux_model.txt')[0])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        bestfit = pars[np.argmax(lnprob)]  # Best fitting parameters\n",
    "        perc = np.percentile(pars, [15.86, 84.14], axis=0)  # 68% interval\n",
    "        sig_bestfit = np.squeeze(np.diff(perc, axis=0)/2)   # half of interval (1sigma)\n",
    "        \n",
    "        # save variables, surf_pot, sigma_pot, qobs_pot, rms_model and flux_model\n",
    "        \n",
    "        # jam the best fit\n",
    "        jam, surf_potential = jam_bestfit(bestfit, **kwargs)\n",
    "        rms_model = jam.model\n",
    "        flux_model = jam.flux\n",
    "\n",
    "    print(\"\\nBest-fitting parameters and 1sigma errors:\")\n",
    "    for label, best, sig in zip(labels, bestfit, sig_bestfit):\n",
    "        print(f\"   {label} = {best:#.4g} +/- {sig:#.2g}\")\n",
    "\n",
    "    # Produce final corner plot without trial values and with best fitting JAM\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.clf()\n",
    "    corner_plot(pars, lnprob, labels=labels, extents=bounds, fignum=1)\n",
    "    logprob = jam_prob_func(bestfit, **kwargs)  # Compute model at best fit location\n",
    "    chi2 = -2*logprob\n",
    "                              \n",
    "    dx = 0.24\n",
    "    yfac = 0.87\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches((12,12))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    i = 0                          \n",
    "    # annotate the model results\n",
    "    plt.annotate(f'chi2 = {chi2}', (0.30, 0.90), xycoords='figure fraction', fontsize=16)\n",
    "    for label, best, sig in zip(labels, bestfit, sig_bestfit):\n",
    "        string = f\"   {label} = {best:#.4g} ± {sig:#.2g}\"\n",
    "        plt.annotate(string, (0.30, 0.87-i*0.03), xycoords='figure fraction', fontsize=16) \n",
    "        i = i+1\n",
    "    \n",
    "                                \n",
    "    #print(xbin.shape, ybin.shape, rms_model.shape, flux_model.shape)\n",
    "                                 \n",
    "    # plot data\n",
    "    fig.add_axes([0.69, 0.99 - dx*yfac, dx, dx*yfac])  # left, bottom, xsize, ysize\n",
    "    rms1 = rms.copy()\n",
    "    rms1[goodbins] = symmetrize_velfield(xbin[goodbins], ybin[goodbins], rms[goodbins])\n",
    "    vmin, vmax = np.percentile(rms1[goodbins], [0.5, 99.5])\n",
    "    plot_velfield(xbin, ybin, rms1, vmin=vmin, vmax=vmax, linescolor='w', \n",
    "                  colorbar=1, label=r\"Data $V_{\\rm rms}$ (km/s)\", flux=flux_model, nodots=True)\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.ylabel('arcsec')\n",
    "    \n",
    "    # plot model\n",
    "    fig.add_axes([0.69, 0.98 - 2*dx*yfac, dx, dx*yfac])  # left, bottom, xsize, ysize\n",
    "    plot_velfield(xbin, ybin, rms_model, vmin=vmin, vmax=vmax, linescolor='w',\n",
    "                  colorbar=1, label=r\"Model $V_{\\rm rms}$ (km/s)\", flux=flux_model, nodots=True)\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.ylabel('arcsec')\n",
    "    if save==True:\n",
    "        plt.savefig(f'{model_dir}{obj_name}_corner_plot_{model_name}_{date_time}.png', bbox_inches='tight')\n",
    "        plt.savefig(f'{model_dir}{obj_name}_corner_plot_{model_name}_{date_time}.pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.pause(1)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "                                                                \n",
    "        \n",
    "    return surf_potential, rms_model, flux_model, bestfit, perc, sig_bestfit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to view previous samplings\n",
    "\n",
    "def get_best_param_err (obj_name, SN, model, anisotropy, align, model_dir=None, date_time=None, run_id=None):\n",
    "\n",
    "    '''\n",
    "    obj_name and number steps to try it out. Start all with the same priors.\n",
    "    '''\n",
    "\n",
    "    obj_abbr = obj_name[4:9] # e.g. J0029\n",
    "    #zlens = zlens[i]\n",
    "    #distance = cosmo.angular_diameter_distance(zlens).value\n",
    "\n",
    "    #mos_dir = f'{mosaics_dir}{obj_name}/' # directory with all files of obj_name\n",
    "    kin_dir = f'{kinematics_dir}{obj_name}/'\n",
    "    #jam_dir = f'{jam_output_dir}{obj_name}/'\n",
    "    \n",
    "    if obj_abbr=='J0330':\n",
    "        target_kin_dir = f'{kin_dir}target_sn_{SN}/{obj_name}_{SN}_final_kinematics/no_g/'\n",
    "    else:\n",
    "        target_kin_dir = f'{kin_dir}target_sn_{SN}/{obj_name}_{SN}_marginalized_gnog_final_kinematics/'\n",
    "    target_jam_dir = f'{jam_dir}target_sn_{SN}/'\n",
    "    \n",
    "    # Get model directory\n",
    "    if model_dir is not None:\n",
    "        model_dir = f'{model_dir}/'\n",
    "    elif date_time is not None and run_id is None:\n",
    "        model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_{SN}_{model}_{anisotropy}_{align}/'\n",
    "    elif date_time is None:\n",
    "        date_time = datetime.now().strftime(\"%Y_%m_%d\")#-%I_%M_%S_%p\")\n",
    "        model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_{SN}_{model}_{anisotropy}_{align}/'\n",
    "    elif date_time is not None and run_id is not None:\n",
    "        model_dir =  f'{target_jam_dir}{obj_name}_model_{date_time}_v{run_id}_{SN}_{model}_{anisotropy}_{align}/'   \n",
    "    else:\n",
    "        print('something wrong')\n",
    "    \n",
    "    #\n",
    "    bestfit = np.genfromtxt(glob.glob(f'{model_dir}*_bestfit_parameters.txt', delimiter=''))\n",
    "    err = np.genfromtxt(glob.glob(f'{model_dir}*_bestfit_parameters_error.txt', delimiter='')\n",
    "    pars = np.genfromtxt(glob.glob(f'{model_dir}*_parameters_fit.txt', delimiter='')\n",
    "    lnprob = np.genfromtxt(glob.glob(f'{model_dir}*_likelihood.txt', delimiter='') \n",
    "    bounds = np.genfromtxt(glob.glob(f'{model_dir}*_bounds.txt', delimiter='')\n",
    "    rms_model = np.genfromtxt(glob.glob(f'{model_dir}*_rms_model.txt', delimiter='')\n",
    "    #print(labels)\n",
    "    with open(glob.glob(f'{model_dir}*_kwargs.pkl\", \"rb\") as f:\n",
    "        kwargs = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    chi2 = -2*jam_lnprob(bestfit, **kwargs)  # Compute chi2 of model at best fit location\n",
    "    \n",
    "    return bestfit, err, pars, lnprob, chi2, bounds, rms_model#, labels\n",
    "    \n",
    "# weighted gaussian to compare the models..\n",
    "def weighted_gaussian(xx, mu, sig, c2):\n",
    "    yy = np.zeros(shape=xx.shape)\n",
    "    for i in range(len(xx)):\n",
    "        yy[i] = np.exp(-np.power(xx[i] - mu, 2.) / (2 * np.power(sig, 2.))) * np.exp(-0.5 * c2)\n",
    "    return yy\n",
    "\n",
    "\n",
    "def get_labels(model, anisotropy):\n",
    "    if model=='power_law':\n",
    "        if anisotropy=='const':              \n",
    "            labels = [r'$\\gamma$', r\"$q_{\\rm min}$\", r\"$\\sigma_z/\\sigma_R$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "        elif anisotropy=='OM':\n",
    "            labels = [r'$\\gamma$', r\"$q_{\\rm min}$\", r\"$a_{ani}$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "    elif model=='nfw':\n",
    "        if anisotropy=='const':\n",
    "            labels = [r\"$f_{\\rm DM}$\", r\"$q_{\\rm min}$\", r\"$\\sigma_z/\\sigma_R$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "        elif anisotropy=='OM':     \n",
    "            labels = [r\"$f_{\\rm DM}$\", r\"$q_{\\rm min}$\", r\"$a_{ani}$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to bring in multiple... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/data/raw_data/KECK_KCWI_SLACS_kinematics_shawn/jam_outputs/SDSSJ1621+3931/target_sn_15/SDSSJ1621+3931_model_2023_06_01_v1_15_power_law_const_sph_adamet/SDSSJ1621+3931_2023_06_01_bestfit_parameters.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cfe9449b7a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{jam_output_dir}{obj_name}/target_sn_{SN}/*_{date_time}_v{run_id}_{model}_{anisotropy}_{align}_{sampler}*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mget_best_param_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manisotropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#get_best_param_err(obj_name, SN, model, anisotropy, align, date_time='2023_06_01', run_id=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# summary_plot(obj_name, date_time, model_dir, jam_prob_func, model_name, load=True, save=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c9362284b1f7>\u001b[0m in \u001b[0;36mget_best_param_err\u001b[0;34m(obj_name, SN, model, anisotropy, align, model_dir, date_time, run_id)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mbestfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_dir}{obj_name}_{date_time}_bestfit_parameters.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_dir}{obj_name}_{date_time}_bestfit_parameters_error.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_dir}{obj_name}_{date_time}_parameters_fit.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /data/raw_data/KECK_KCWI_SLACS_kinematics_shawn/jam_outputs/SDSSJ1621+3931/target_sn_15/SDSSJ1621+3931_model_2023_06_01_v1_15_power_law_const_sph_adamet/SDSSJ1621+3931_2023_06_01_bestfit_parameters.txt not found."
     ]
    }
   ],
   "source": [
    "obj_name = obj_names[-4]\n",
    "\n",
    "SN=15\n",
    "\n",
    "model='*' # wildcard should select all of them\n",
    "anisotropy='*'\n",
    "align='*'\n",
    "sampler='*'\n",
    "\n",
    "date_time='2023_06_01'\n",
    "run_id = '1'\n",
    "#model_dir = \n",
    "\n",
    "for model_dir in glob.glob(f'{jam_output_dir}{obj_name}/target_sn_{SN}/*_{date_time}_v{run_id}_{model}_{anisotropy}_{align}_{sampler}*'):\n",
    "    \n",
    "    get_best_param_err(obj_name, SN, model, anisotropy, align, model_dir=model_dir, date_time=date_time, run_id=run_id)\n",
    "#get_best_param_err(obj_name, SN, model, anisotropy, align, date_time='2023_06_01', run_id=None)\n",
    "# summary_plot(obj_name, date_time, model_dir, jam_prob_func, model_name, load=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jam_lnprior (pars, bounds, mu, sigma, prior_type):\n",
    "    '''\n",
    "    Calculate the prior likelihood for the sampled parameters\n",
    "    pars\n",
    "    mu - mean of prior\n",
    "    sigma - width of prior\n",
    "    prior_type - uniform, gaussian, log_uniform, log_normal\n",
    "    '''\n",
    "    \n",
    "    pars = np.array(pars)\n",
    "    mu = np.array(mu)\n",
    "    sigma = np.array(sigma)\n",
    "\n",
    "    if any(pars < bounds[0]) or any(pars > bounds[1]):\n",
    "        lnprior = -np.inf\n",
    "    \n",
    "    else:\n",
    "        lnprior=np.ones_like(pars)\n",
    "        for i in range(len(pars)):\n",
    "            if prior_type[i]=='uniform':\n",
    "                lnprior[i]=0.\n",
    "            elif prior_type[i]=='gaussian':\n",
    "                lnprior[i]=np.log(1.0/(np.sqrt(2*np.pi)*sigma[i]))-0.5*(pars[i]-mu[i])**2/sigma[i]**2\n",
    "            \n",
    "    return np.sum(lnprior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up new anisotropy functions and probability functions to be fit\n",
    "\n",
    "def jam_lnprob (pars, bounds=None, p0=None, sigpar=None, prior_type=None,\n",
    "                surf_lum=None, sigma_lum=None, qobs_lum=None, distance=None,\n",
    "                  xbin=None, ybin=None, sigmapsf=None, normpsf=None, goodbins=None,\n",
    "                   rms=None, erms=None, pixsize=None, reff=None, plot=True, \n",
    "                 model=None, anisotropy=None, align=None, labels=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the probability of the model, given the data, assuming constant priors\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lnprior = jam_lnprior (pars, bounds, mu=p0, sigma=sigpar, prior_type=prior_type)\n",
    "    \n",
    "    if np.isinf(lnprior) or np.isnan(lnprior):\n",
    "        return -np.inf\n",
    "    \n",
    "    else:\n",
    "        # parameters for fitting\n",
    "        # Mass model\n",
    "        if model=='power_law':\n",
    "            gamma, q, anis_param, lg_ml = pars\n",
    "            # let f_dm = 0 for a power law\n",
    "            f_dm = 0\n",
    "        elif model=='nfw':\n",
    "            f_dm, q, anis_param, lg_ml = pars\n",
    "            # gamma = -1 for NFW\n",
    "            gamma = -1\n",
    "\n",
    "        # Anisotropy is dependent on model\n",
    "        if anisotropy=='const':\n",
    "            ratio = anis_param\n",
    "            beta = np.full_like(qobs_lum, 1 - ratio**2)   # assume constant anisotropy, anis_param is the ratio of q_t/q_r\n",
    "        elif anisotropy=='OM':\n",
    "            a_ani = anis_param # anis_param is the anisotropy transition radius in units of the effective radius\n",
    "            r_a = a_ani*reff\n",
    "            beta_0 = 0 # fully isotropic\n",
    "            beta_inf = 1 # fully radially anisotropic\n",
    "            alpha = 2 # sharpness of transition\n",
    "            beta = [r_a, beta_0, beta_inf, alpha]\n",
    "\n",
    "        # Sample inclination using min(q), with Equation (14) of Cappellari (2008)\n",
    "        qmin = np.min(qobs_lum)\n",
    "        inc = np.degrees(np.arctan2(np.sqrt(1 - qmin**2), np.sqrt(qmin**2 - q**2)))\n",
    "\n",
    "        # Obtain total mass profile\n",
    "        surf_pot, sigma_pot, qobs_pot = total_mass_mge(surf_lum, sigma_lum, qobs_lum, reff,\n",
    "                                                       gamma, f_dm, inc, lg_ml, model, plot=plot)\n",
    "\n",
    "        # ignore central black hole\n",
    "        mbh=0.\n",
    "\n",
    "        # make the JAM model\n",
    "        jam = jam_axi_proj(surf_lum, sigma_lum, qobs_lum, surf_pot, sigma_pot, qobs_pot,\n",
    "                           inc, mbh, distance, xbin, ybin, plot=plot, pixsize=pixsize, quiet=1,\n",
    "                           sigmapsf=sigmapsf, normpsf=normpsf, goodbins=goodbins, align=align,\n",
    "                           beta=beta, data=rms, errors=erms, ml=1, nodots=True)\n",
    "\n",
    "        resid = (rms[goodbins] - jam.model[goodbins])/erms[goodbins]\n",
    "        chi2 = resid @ resid\n",
    "        lnprob = -0.5*chi2 + lnprior\n",
    "\n",
    "    return lnprob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jam_bestfit (pars, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the model of the bestfit parameters\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    surf_lum=kwargs['surf_lum']\n",
    "    sigma_lum=kwargs['sigma_lum']\n",
    "    qobs_lum=kwargs['qobs_lum']\n",
    "    distance=kwargs['distance']\n",
    "    xbin=kwargs['xbin']\n",
    "    ybin=kwargs['ybin']\n",
    "    sigmapsf=kwargs['sigmapsf']\n",
    "    normpsf=kwargs['normpsf']\n",
    "    goodbins=kwargs['goodbins']\n",
    "    rms=kwargs['rms']\n",
    "    erms=kwargs['erms']\n",
    "    pixsize=kwargs['pixsize']\n",
    "    reff=kwargs['reff']\n",
    "    plot=kwargs['plot']\n",
    "    model=kwargs['model']\n",
    "    anisotropy=kwargs['anisotropy']\n",
    "    align=kwargs['align']\n",
    "    \n",
    "    # parameters for fitting\n",
    "    # Mass model\n",
    "    if model=='power_law':\n",
    "        gamma, q, anis_param, lg_ml = pars\n",
    "        # let f_dm = 0 for a power law\n",
    "        f_dm = 0\n",
    "    elif model=='nfw':\n",
    "        f_dm, q, anis_param, lg_ml = pars\n",
    "        # gamma = -1 for NFW\n",
    "        gamma = -1\n",
    "        \n",
    "    # Anisotropy is dependent on model\n",
    "    if anisotropy=='const':\n",
    "        ratio = anis_param\n",
    "        beta = np.full_like(qobs_lum, 1 - ratio**2)   # assume constant anisotropy, anis_param is the ratio of q_t/q_r\n",
    "    elif anisotropy=='OM':\n",
    "        a_ani = anis_param # anis_param is the anisotropy transition radius in units of the effective radius\n",
    "        r_a = a_ani*reff\n",
    "        beta_0 = 0 # fully isotropic\n",
    "        beta_inf = 1 # fully radially anisotropic\n",
    "        alpha = 2 # sharpness of transition\n",
    "        beta = [r_a, beta_0, beta_inf, alpha]\n",
    "\n",
    "    # Sample inclination using min(q), with Equation (14) of Cappellari (2008)\n",
    "    qmin = np.min(qobs_lum)\n",
    "    inc = np.degrees(np.arctan2(np.sqrt(1 - qmin**2), np.sqrt(qmin**2 - q**2)))\n",
    "    \n",
    "    # Obtain total mass profile\n",
    "    surf_pot, sigma_pot, qobs_pot = total_mass_mge(surf_lum, sigma_lum, qobs_lum, reff,\n",
    "                                                   gamma, f_dm, inc, lg_ml, model, plot=plot)\n",
    "    \n",
    "    surf_potential = np.stack((surf_pot, sigma_pot, qobs_pot))\n",
    "    \n",
    "    # ignore central black hole\n",
    "    mbh=0.\n",
    "    \n",
    "    print('JAMMING the best fit model')\n",
    "    \n",
    "    # make the JAM model\n",
    "    jam = jam_axi_proj(surf_lum, sigma_lum, qobs_lum, surf_pot, sigma_pot, qobs_pot,\n",
    "                       inc, mbh, distance, xbin, ybin, plot=True, pixsize=pixsize, quiet=1,\n",
    "                       sigmapsf=sigmapsf, normpsf=normpsf, goodbins=goodbins, align=align,\n",
    "                       beta=beta, data=rms, errors=erms, ml=1, nodots=True)\n",
    "    \n",
    "    return jam, surf_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "def power_law_mge (gamma, q, rbreak, plot=False):\n",
    "    \"\"\"\n",
    "    gamma - power law slope (2 = isothermal)\n",
    "    q - mean q from gaussian components of light profile\n",
    "    rbreak - some radius... make it big?\n",
    "    Haven't quite worked this one out yet...\n",
    "    \"\"\"\n",
    "    # The fit is performed in log spaced radii from 1\" to 10*rbreak\n",
    "    n = 1000     # Number of values to sample the gNFW profile for the MGE fit\n",
    "    r = np.geomspace(0.01, rbreak, n)   # logarithmically spaced radii in arcsec\n",
    "    \n",
    "    rho = (3 - gamma) / 2 * (rbreak/r)**(gamma-1)\n",
    "    \n",
    "    m = mge_fit_1d(r, rho, ngauss=15, inner_slope=20, outer_slope=0, quiet=1, plot=plot) # this creates a circular gaussian with sigma=sigma_x (i.e. along the major axis)\n",
    "    \n",
    "    surf_pot, sigma_pot = m.sol           # Peak surface density and sigma # 05/22/23 - I think this actually gives the \"total counts\", not peak surface density\n",
    "    surf_pot = surf_pot / np.sqrt(2*np.pi) / sigma_pot # THIS should give peak surface density\n",
    "    qobs_pot = np.ones_like(surf_pot)*q   # Multiply by q to convert to elliptical Gaussians where sigma is along the major axis... I'm not sure if this is perfectly correct\n",
    "\n",
    "    return surf_pot, sigma_pot, qobs_pot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "\n",
    "def dark_halo_mge (gamma, rbreak, plot=False):\n",
    "    \"\"\"\n",
    "    Returns the MGE parameters for a generalized spherical NFW dark halo profile\n",
    "    https://ui.adsabs.harvard.edu/abs/2001ApJ...555..504W\n",
    "    Inputs:\n",
    "        gamma - inner profile slope (logarithmic slope, i.e. slope when plotted as log(rho) to log(r), < 0\n",
    "                if gamma = -1, this is standard NFW profile\n",
    "        rbreak - break radius, transition from inner slope to outer slope (of -3)\n",
    "    Outputs:\n",
    "        surf_dm, sigma_dm, qobs_dm - MGE parameters of dark halo surface potential (peak surface density, sigma of Gaussians, and axial ratio (1 because it's spherical)\n",
    "        \n",
    "    \"\"\"\n",
    "    # The fit is performed in log spaced radii from 1\" to 10*rbreak\n",
    "    n = 1000     # Number of values to sample the gNFW profile for the MGE fit\n",
    "    r = np.geomspace(0.01, rbreak*10, n)   # logarithmically spaced radii in arcsec\n",
    "    rho = nfw_generalized_model (r, gamma, rbreak)\n",
    "    m = mge_fit_1d(r, rho, ngauss=15, inner_slope=20, outer_slope=0, quiet=1, plot=plot)\n",
    "\n",
    "    surf_dm, sigma_dm = m.sol           # Peak surface density and sigma # 05/22/23 - I think this actually gives the \"total counts\", not peak surface density\n",
    "    surf_dm = surf_dm / np.sqrt(2*np.pi) / sigma_dm # THIS should give peak surface density\n",
    "    qobs_dm = np.ones_like(surf_dm)     # Assume spherical dark halo\n",
    "\n",
    "    return surf_dm, sigma_dm, qobs_dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_mass_mge (surf_lum, sigma_lum, qobs_lum, reff, gamma, f_dm, inc, lg_ml, model, plot=False):\n",
    "    \"\"\"\n",
    "    Combine the MGE from a dark halo and the MGE from the stellar surface\n",
    "    brightness in such a way to have a given dark matter fractions f_dm\n",
    "    inside a sphere of radius one half-light radius reff\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if model == 'nfw':\n",
    "        \n",
    "        gamma = -1\n",
    "        rbreak = 20*reff # much bigger than data # should this be a free parameter?\n",
    "\n",
    "        surf_dm, sigma_dm, qobs_dm = dark_halo_mge(gamma, rbreak, plot)\n",
    "        #plt.pause(1)\n",
    "\n",
    "        stars_lum_re = mge_radial_mass(surf_lum, sigma_lum, qobs_lum, inc, reff)\n",
    "        dark_mass_re = mge_radial_mass(surf_dm, sigma_dm, qobs_dm, inc, reff)\n",
    "\n",
    "        # Find the scale factor needed to satisfy the following definition\n",
    "        # f_dm == dark_mass_re*scale/(stars_lum_re + dark_mass_re*scale)\n",
    "        scale = (f_dm*stars_lum_re)/(dark_mass_re*(1 - f_dm))\n",
    "\n",
    "        surf_pot = np.append(surf_lum, surf_dm*scale)   # Msun/pc**2. DM scaled so that f_DM(Re)=f_DM\n",
    "        sigma_pot = np.append(sigma_lum, sigma_dm)      # Gaussian dispersion in arcsec\n",
    "        qobs_pot = np.append(qobs_lum, qobs_dm)\n",
    "        \n",
    "        # Note: I multiply surf_pot by ml=10**lg_ml, while I set the keyword ml=1\n",
    "        # Both the stellar and dark matter increase by ml and f_dm is unchanged\n",
    "        surf_pot *= 10**lg_ml\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif model == 'nfw_general':\n",
    "        \n",
    "        gamma = gamma\n",
    "        rbreak = 20*reff # much bigger than data\n",
    "\n",
    "        surf_dm, sigma_dm, qobs_dm = dark_halo_mge(gamma, rbreak, plot)\n",
    "\n",
    "        stars_lum_re = mge_radial_mass(surf_lum, sigma_lum, qobs_lum, inc, reff)\n",
    "        dark_mass_re = mge_radial_mass(surf_dm, sigma_dm, qobs_dm, inc, reff)\n",
    "\n",
    "        # Find the scale factor needed to satisfy the following definition\n",
    "        # f_dm == dark_mass_re*scale/(stars_lum_re + dark_mass_re*scale)\n",
    "        scale = (f_dm*stars_lum_re)/(dark_mass_re*(1 - f_dm))\n",
    "\n",
    "        surf_pot = np.append(surf_lum, surf_dm*scale)   # Msun/pc**2. DM scaled so that f_DM(Re)=f_DM\n",
    "        sigma_pot = np.append(sigma_lum, sigma_dm)      # Gaussian dispersion in arcsec\n",
    "        qobs_pot = np.append(qobs_lum, qobs_dm)\n",
    "        \n",
    "        # Note: I multiply surf_pot by ml=10**lg_ml, while I set the keyword ml=1\n",
    "        # Both the stellar and dark matter increase by ml and f_dm is unchanged\n",
    "        surf_pot *= 10**lg_ml\n",
    "        \n",
    "        \n",
    "    elif model == 'power_law':\n",
    "        \n",
    "        gamma = gamma\n",
    "        rbreak = 100*reff # much bigger than data\n",
    "        \n",
    "        # take counts-weighted average of light profile q\n",
    "        q_mean = np.average(qobs_lum, weights=surf_lum)\n",
    "        \n",
    "        surf_pot, sigma_pot, qobs_pot = power_law_mge(gamma, q_mean, rbreak, plot)\n",
    "        #plt.pause(1)\n",
    "        \n",
    "        lum_re = mge_radial_mass(surf_lum, sigma_lum, qobs_lum, inc, reff)\n",
    "        mass_re = mge_radial_mass(surf_pot, sigma_pot, qobs_pot, inc, reff)\n",
    "        \n",
    "        # scale so that mass to light ratio at effective radius is the mass to light ratio input\n",
    "        #print(mass_re/lum_re)\n",
    "        ml = 10**lg_ml\n",
    "        scale = lum_re/mass_re * ml\n",
    "        # Multiply the surface mass by the scale\n",
    "        surf_pot *= scale\n",
    "\n",
    "    return surf_pot, sigma_pot, qobs_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the priors if none are given\n",
    "\n",
    "def get_priors (model, anisotropy, qobs, p0=None, bounds=None, sigpar=None, prior_type=None):\n",
    "    \n",
    "    if prior_type==None:\n",
    "        prior_type=['uniform','uniform','uniform','uniform']\n",
    "    \n",
    "    if model=='power_law':\n",
    "        if anisotropy=='const':\n",
    "            if p0==None:\n",
    "                # Starting guess, e.g. from a previous least-squares fit\n",
    "                gamma0 = 2.0             # inner power law slope\n",
    "                q0 = 1/2*np.median(qobs)        # Axial ratio of the flattest MGE Gaussian, make it about half the value of the median axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                ratio0 = 0.8            # Anisotropy ratio sigma_z/sigma_R\n",
    "                lg_ml0 = 1.5 # change this... my m/l is still weird... 0.8 # np.log10(5)  # M/L from the first fit... I sample the M/L logarithmically\n",
    "                p0 = [gamma0, q0, ratio0, lg_ml0]\n",
    "                bounds = [[1, 0.051, 0.01, lg_ml0-1.0], \n",
    "                          [3, qbound, 1.0, lg_ml0+1.0]]\n",
    "                sigpar = np.array([0.1, 0.1, 0.1, 0.1])  # crude estimate of uncertainties\n",
    "            else:\n",
    "                # need to input the qbounds from the MGE fit\n",
    "                q0 = 1/2*np.median(qobs)        # Axial ratio of the flattest MGE Gaussian, make it about half the value of the median axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                #p0[1] = q0\n",
    "                bounds[1][1] = qbound                \n",
    "            labels = [r'$\\gamma$', r\"$q_{\\rm min}$\", r\"$\\sigma_z/\\sigma_R$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "        elif anisotropy=='OM':\n",
    "            if p0==None:\n",
    "                # Starting guess, e.g. from a previous least-squares fit\n",
    "                gamma0 = 2.0             # inner power law slope\n",
    "                q0 = 0.6 # 1/2*np.median(qobs)         #  Axial ratio of the flattest MGE Gaussian\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                anis_rad0 = 0.5            # Anisotropy radius 1.0\n",
    "                lg_ml0 = 1.5 # np.log10(5)  # M/L from the first fit... I sample the M/L logarithmically\n",
    "                p0 = [gamma0, q0, anis_rad0, lg_ml0]\n",
    "                bounds = [[1, 0.051, 0.1, lg_ml0-1.0], \n",
    "                          [3, qbound, 5.0, lg_ml0+1.0]]\n",
    "                sigpar = np.array([0.1, 0.1, 0.5, 0.1])  # crude estimate of uncertainties    \n",
    "            else:\n",
    "                # need to input the qbounds from the MGE fit\n",
    "                q0 = 1/2*np.median(qobs)        # Axial ratio of the flattest MGE Gaussian, make it about half the value of the median axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                #p0[1] = q0\n",
    "                bounds[1][1] = qbound     \n",
    "            labels = [r'$\\gamma$', r\"$q_{\\rm min}$\", r\"$a_{ani}$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "    elif model=='nfw':\n",
    "        if anisotropy=='const':\n",
    "            if p0==None:\n",
    "                # Starting guess, e.g. from a previous least-squares fit\n",
    "                f_dm0 = 0.15           # Dark matter fraction inside a sphere of radius Re\n",
    "                q0 = 1/2*np.median(qobs)              # Axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                ratio0 = 0.8            # Anisotropy ratio sigma_z/sigma_R\n",
    "                lg_ml0 = 1.5 # M/L from the first fit... I sample the M/L logarithmically\n",
    "                p0 = [f_dm0, q0, ratio0, lg_ml0]\n",
    "                bounds = [[0, 0.051, 0.01, lg_ml0-1.0], \n",
    "                          [0.8, qbound, 2.0, lg_ml0+1.0]]\n",
    "                sigpar = np.array([0.05, 0.15, 0.15, 0.1])  # crude estimate of uncertainties\n",
    "            else:\n",
    "                # need to input the qbounds from the MGE fit\n",
    "                q0 = 1/2*np.median(qobs)        # Axial ratio of the flattest MGE Gaussian, make it about half the value of the median axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                #p0[1] = q0\n",
    "                bounds[1][1] = qbound     \n",
    "            labels = [r\"$f_{\\rm DM}$\", r\"$q_{\\rm min}$\", r\"$\\sigma_z/\\sigma_R$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "        elif anisotropy=='OM':\n",
    "            if p0==None:\n",
    "                # Starting guess, e.g. from a previous least-squares fit\n",
    "                f_dm0 = 0.15           # Dark matter fraction inside a sphere of radius Re\n",
    "                q0 = 1/2*np.median(qobs)              # Axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                anis_rad0 = 0.5            # Anisotropy radius 1.0\n",
    "                lg_ml0 = 1.5 # M/L from the first fit... I sample the M/L logarithmically\n",
    "                p0 = [f_dm0, q0, anis_rad0, lg_ml0]\n",
    "                bounds = [[0, 0.051, 0.1, lg_ml0-1.0], \n",
    "                          [0.8, qbound, 5.0, lg_ml0+1.0]]\n",
    "                sigpar = np.array([0.05, 0.15, 0.15, 0.1])  # crude estimate of uncertainties\n",
    "            else:\n",
    "                # need to input the qbounds from the MGE fit\n",
    "                q0 = 1/2*np.median(qobs)        # Axial ratio of the flattest MGE Gaussian, make it about half the value of the median axial ratio\n",
    "                qbound = np.min(qobs) # upper bound for axis ratio\n",
    "                #p0[1] = q0\n",
    "                bounds[1][1] = qbound                 \n",
    "            labels = [r\"$f_{\\rm DM}$\", r\"$q_{\\rm min}$\", r\"$a_{ani}$\", r\"$\\lg(M_\\ast/L)$\"]\n",
    "\n",
    "    return p0, bounds, sigpar, prior_type, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciton to create model directory\n",
    "\n",
    "def create_model_directory (target_jam_dir, obj_name, SN, model, anisotropy, align, sampler, date_time=None, overwrite=False, run_id=None):\n",
    "    model_name = f'{SN}_{model}_{anisotropy}_{align}_{sampler}'\n",
    "    if date_time is None:\n",
    "        date_time = datetime.now().strftime(\"%Y_%m_%d\")#-%I_%M_%S_%p\")   \n",
    "    if run_id is None:\n",
    "        model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_{model_name}/'\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.mkdir(model_dir)\n",
    "        else:\n",
    "            if overwrite==True:\n",
    "                print(f'Files in {model_dir} will be overwritten.')\n",
    "            else:\n",
    "                print('Do not overwrite your files dummy. Adding 1 to run_id to see if it works.')\n",
    "                # try run_id \n",
    "                run_id = 1\n",
    "                model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_v{run_id}_{model_name}/'\n",
    "                if not os.path.exists(model_dir):\n",
    "                    os.mkdir(model_dir)\n",
    "                else:\n",
    "                    print('Who let you do this?')\n",
    "                    #print(babaganoug) # bring error\n",
    "    else:\n",
    "        model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_v{run_id}_{model_name}/'\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.mkdir(model_dir)\n",
    "        else:\n",
    "            if overwrite==True:\n",
    "                print(f'Files in {model_dir} will be overwritten.')\n",
    "            else:\n",
    "                print('Do not overwrite your files dummy. Adding 1 to run_id to see if it works.')\n",
    "                # try 1 run_id higher\n",
    "                run_id = run_id + 1\n",
    "                model_dir = f'{target_jam_dir}{obj_name}_model_{date_time}_v{run_id}_{model_name}/'\n",
    "                if not os.path.exists(model_dir):\n",
    "                    os.mkdir(model_dir)\n",
    "                else:\n",
    "                    print('Who let you do this?')\n",
    "                    #print(babaganoug)\n",
    "                    \n",
    "    return model_dir, model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_jam (obj_name, SN, model, anisotropy, align, sampler, sampler_args, \\\n",
    "               p0=None, bounds=None, sigpar=None, prior_type=None, date_time=None, overwrite=False, run_id=None):\n",
    "    \n",
    "    '''\n",
    "    obj_name and number steps to try it out. Start all with the same priors.\n",
    "    '''\n",
    "\n",
    "    obj_abbr = obj_name[4:9] # e.g. J0029\n",
    "    zlens = paper_table[paper_table['obj_name']==obj_name]['zlens']\n",
    "    distance = cosmo.angular_diameter_distance(zlens).value\n",
    "\n",
    "    mos_dir = f'{mosaics_dir}{obj_name}/' # directory with all files of obj_name\n",
    "    kin_dir = f'{kinematics_dir}{obj_name}/'\n",
    "    jam_dir = f'{jam_output_dir}{obj_name}/'\n",
    "    # create a directory for JAM outputs\n",
    "    Path(jam_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if obj_abbr=='J0330':\n",
    "        target_kin_dir = f'{kin_dir}target_sn_{SN}/{obj_name}_{SN}_final_kinematics/no_g/'\n",
    "    else:\n",
    "        target_kin_dir = f'{kin_dir}target_sn_{SN}/{obj_name}_{SN}_marginalized_gnog_final_kinematics/'\n",
    "    target_jam_dir = f'{jam_dir}target_sn_{SN}/'\n",
    "    # create a directory for JAM outputs\n",
    "    Path(target_jam_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # prepare inputs\n",
    "    surf, sigma, qobs, kcwi_sigmapsf, Vrms, dVrms, V, dV, xbin, ybin, reff = prepare_to_jam(obj_name, target_kin_dir, SN)\n",
    "    \n",
    "    # get distance from z\n",
    "    slacs_data = np.genfromtxt(f'{tables_dir}slacs_tableA1.txt', delimiter='', dtype='U10')\n",
    "    zlens_column = slacs_data[:,3].astype(float)\n",
    "    slacs_table_name = obj_name[4:]\n",
    "    zlens = zlens_column[slacs_data[:,0]==slacs_table_name]\n",
    "    distance = cosmo.angular_diameter_distance(zlens).value\n",
    "    \n",
    "    #############################################################\n",
    "    # JAM Parameters\n",
    "    ##############################################################################\n",
    "    ##############################################################################\n",
    "    \n",
    "    # get priors for sampling\n",
    "    p0, bounds, sigpar, prior_type, labels = get_priors (model, anisotropy, qobs, p0=p0, bounds=bounds, sigpar=sigpar, prior_type=prior_type)\n",
    "            \n",
    "    goodbins = np.isfinite(xbin)  # Here I fit all bins, it's already masked\n",
    "\n",
    "    # These parameters are passed to JAM\n",
    "    kwargs = {'surf_lum': surf, 'sigma_lum': sigma, 'qobs_lum': qobs,\n",
    "              'distance': distance, 'xbin': xbin, 'ybin': ybin, 'sigmapsf': kcwi_sigmapsf,\n",
    "              'normpsf': 1., 'rms':Vrms, 'erms':dVrms, 'pixsize': kcwi_scale,\n",
    "              'goodbins': goodbins, 'plot': False, 'reff':reff, \n",
    "              'model':model, 'anisotropy':anisotropy, 'align':align,\n",
    "              'p0':p0, 'bounds':bounds, 'sigpar':sigpar, 'prior_type':prior_type, 'labels':labels\n",
    "             }\n",
    "\n",
    "    \n",
    "    # make the model directory\n",
    "    model_dir, model_name = create_model_directory (target_jam_dir, obj_name, SN, model, anisotropy, align, sampler, date_time, overwrite, run_id)       \n",
    "    print()\n",
    "    print('Outputs to ', model_dir)\n",
    "    print()\n",
    "    \n",
    "    # Try a light follows mass fit\n",
    "    #premodel= jam_axi_proj(surf, sigma, qobs, surf, sigma, qobs, # takes surf_lum to be also surf_pot\n",
    "    #                   70, 0, distance, xbin, ybin, plot=True, pixsize=kcwi_scale, quiet=1,\n",
    "    #                   sigmapsf=kcwi_sigmapsf, normpsf=1., goodbins=goodbins, align=align,\n",
    "    #                   beta=np.ones_like(surf)*0.2, data=Vrms, errors=dVrms, ml=None, nodots=True)\n",
    "    #print('Pre-model M/L ', premodel.ml)\n",
    "    #plt.pause(1)\n",
    "    #plt.clf()\n",
    "    \n",
    "    #############################################################\n",
    "    # Do the Bayesian fit\n",
    "    ##############################################################################\n",
    "    ##############################################################################\n",
    "\n",
    "    # For now, we have a single function that will work for const/om, and pl/nfw\n",
    "    jam_prob_func=jam_lnprob\n",
    "\n",
    "    if sampler=='adamet':\n",
    "        # Do the fit\n",
    "        print(\"Started AdaMet please wait...\")\n",
    "        print(\"Progress is printed periodically\")\n",
    "        nstep = sampler_args\n",
    "        pos0 = p0 + np.random.normal(0, sigpar, len(p0)) # initialize slightly off # Fix this later\n",
    "        pars, lnprob = adamet(jam_prob_func, pos0, sigpar, bounds, nstep, fignum=1,\n",
    "                              kwargs=kwargs, nprint=nstep/20, labels=labels, seed=2, plot=False)\n",
    "        \n",
    "    elif sampler=='emcee':\n",
    "        # Do the fit\n",
    "        print(\"Started Emcee please wait...\")\n",
    "        print(\"Progress is printed periodically\")\n",
    "        nstep, nwalkers, ndim = sampler_args\n",
    "        # set initial walker positions\n",
    "        walk0 = np.random.uniform(bounds[0], bounds[1], [nwalkers,ndim])\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, jam_prob_func, kwargs=kwargs)\n",
    "        sampler.run_mcmc(walk0, nstep, progress=True)\n",
    "        # save sampler as pickle\n",
    "        f = open(f\"{model_dir}{obj_name}_{date_time}_{model_name}_emcee_sampler.pkl\",\"wb\")\n",
    "        # write the python object (dict) to pickle file\n",
    "        pickle.dump(sampler,f)\n",
    "        # close file\n",
    "        f.close()\n",
    "        pars = sampler.get_chain(flat=True)\n",
    "        lnprob = sampler.get_log_prob(flat=True)\n",
    "        fig = corner.corner(\n",
    "            pars, labels=labels\n",
    "        );\n",
    "        for i in range(ndim):\n",
    "            mcmc = np.percentile(pars[:, i], [16, 50, 84])\n",
    "            q = np.diff(mcmc)\n",
    "            txt = \"\\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}\"\n",
    "            txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "            display(Math(txt))\n",
    "\n",
    "    print('n accepted unique parameters', len(np.unique(pars[:,0])))\n",
    "    \n",
    "    # plot the results, get rms_model and flux_model of best fit\n",
    "    surf_potential, rms_model, flux_model, \\\n",
    "        bestfit, percentiles, sig_bestfit = summary_plot(obj_name, date_time, model_dir, jam_prob_func, model_name,\n",
    "                                                         pars=pars, lnprob=lnprob, labels=labels, bounds=bounds, \n",
    "                                                         kwargs=kwargs, save=True, load=False)\n",
    "\n",
    "    # calculate mass estimate\n",
    "    # mass to light ratio\n",
    "    ml_ratio = bestfit[3]\n",
    "    dml = sig_bestfit[3]\n",
    "    # get the total luminosity\n",
    "    _, _, _, lum_tot = mge_half_light_isophote(surf, sigma, qobs, distance)\n",
    "    # multiply by the mass to light ratio\n",
    "    total_mass = 10**ml_ratio * lum_tot\n",
    "    total_mass_err = 10**dml * lum_tot\n",
    "    total_mass_sci_not = \"{:.2e}\".format(total_mass)\n",
    "    total_mass_err_sci_not = \"{:.2e}\".format(total_mass_err)\n",
    "    print(f'Dynamical mass estimate: {total_mass_sci_not} +/- {total_mass_err_sci_not}')\n",
    "    q = bestfit[1]\n",
    "    print(f'Inclination: ', np.degrees(np.arctan2(np.sqrt(1 - np.min(qobs)**2), np.sqrt(np.min(qobs)**2 - q**2))))\n",
    "\n",
    "    # save parameters from fit\n",
    "    save_fit_parameters(model_dir, model_name, obj_name, date_time, bestfit, sig_bestfit, percentiles, pars, lnprob, p0, sigpar, \n",
    "                        bounds, labels, surf_potential, rms_model, flux_model, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "__________________\n",
    "\n",
    "# BREAK\n",
    "__________________\n",
    "__________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
